{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/IMDB Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking if data is biased\n",
    "\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing HTML strips\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# manual way\n",
    "# df['review'].apply(lambda x: x.replace('<br /><br />', ''))\n",
    "\n",
    "def html_strips_remove(text):\n",
    "    text = re.sub('<\\w*\\s*/>', '', text)\n",
    "    return text\n",
    "df['review'] = df['review'].apply(html_strips_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_char_remove(text):\n",
    "    text = re.sub('[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "df['review'] = df['review'].apply(sp_char_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "df['review'] = df['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop = set( nltk.corpus.stopwords.words('English'))\n",
    "stop = [word.lower() for word in nltk.corpus.stopwords.words('English')]\n",
    "\n",
    "\n",
    "# removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    filtered_list=[]\n",
    "    split_text = text.split(' ')\n",
    "    for word in split_text:\n",
    "        if word.lower() in stop:\n",
    "            pass\n",
    "        else:\n",
    "            filtered_list.append(word)\n",
    "    filtered_text = ' '.join(filtered_list) \n",
    "    return filtered_text\n",
    "\n",
    "df['review'] = df['review'].apply(remove_stopwords)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text1 = df['review'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Labeling sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = sklearn.preprocessing.LabelBinarizer()\n",
    "df['lb_sentiment'] = lb.fit_transform(df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lb_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch 1 Oz episod youll ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl product film techniqu veri unassu...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic famili littl boy jake think zombi hi clo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  lb_sentiment\n",
       "0  one review ha mention watch 1 Oz episod youll ...  positive             1\n",
       "1  wonder littl product film techniqu veri unassu...  positive             1\n",
       "2  thought thi wa wonder way spend time hot summe...  positive             1\n",
       "3  basic famili littl boy jake think zombi hi clo...  negative             0\n",
       "4  petter mattei love time money visual stun film...  positive             1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['review']\n",
    "y = df['lb_sentiment']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Vectorizer\n",
    "cv_vect = CountVectorizer()\n",
    "cv_x_train_vector = cv_vect.fit_transform(x_train)\n",
    "cv_x_test_vector = cv_vect.transform(x_test)\n",
    "\n",
    "# print(x_train[0])\n",
    "# print(x_train_vector[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tv_vectorizer = TfidfVectorizer()\n",
    "\n",
    "tv_x_train_vector = tv_vectorizer.fit_transform(x_train)\n",
    "tv_x_test_vector = tv_vectorizer.transform(x_test)\n",
    "\n",
    "# print(x_train[0])\n",
    "# print(x_train_vector[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 155950)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_x_train_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 155950)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_x_train_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Accuracy:  0.5458\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "cv_svm = sklearn.svm.SVC(verbose=1, max_iter=500)\n",
    "cv_svm.fit(cv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = cv_svm.predict(cv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "cv_svm_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer SVM Accuracy: ', cv_svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\svm\\_base.py:246: ConvergenceWarning: Solver terminated early (max_iter=500).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFVID Vectorizer SVM Accuracy:  0.7359\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "tv_svm = sklearn.svm.SVC(verbose=1, max_iter=500)\n",
    "tv_svm.fit(tv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = tv_svm.predict(tv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "tv_svm_acc = accuracy_score(y_test, y_pred)\n",
    "print('TFVID Vectorizer SVM Accuracy: ', tv_svm_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.73      0.75      0.74      4988\n",
      "    Positive       0.74      0.73      0.73      5012\n",
      "\n",
      "    accuracy                           0.74     10000\n",
      "   macro avg       0.74      0.74      0.74     10000\n",
      "weighted avg       0.74      0.74      0.74     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification_report_tfidf\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))  # alphabatical order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer Accuracy:  0.8818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   25.6s finished\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "cv_lr = sklearn.linear_model.LogisticRegression(verbose=1, max_iter=500)\n",
    "cv_lr.fit(cv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = cv_lr.predict(cv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "cv_lr_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer Logistic Regression Accuracy: ', cv_lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFVID Logistic Regression Accuracy:  0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    5.5s finished\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "tv_lr = sklearn.linear_model.LogisticRegression(verbose=1, max_iter=500)\n",
    "tv_lr.fit(tv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = tv_lr.predict(tv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "tv_lr_acc = accuracy_score(y_test, y_pred)\n",
    "print('TFVID Logistic Regression Accuracy: ', tv_lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.88      0.86      4988\n",
      "    Positive       0.87      0.84      0.86      5012\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification_report_tfidf\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))  # alphabatical order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent or Linear support vector machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer SGD Accuracy:  0.8764\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "cv_sgd = sklearn.linear_model.SGDClassifier(verbose=0, max_iter=500)\n",
    "cv_sgd.fit(cv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = cv_sgd.predict(cv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "cv_sgd_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer SGD Accuracy: ', cv_sgd_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 47.86, NNZs: 97485, Bias: 0.050102, T: 40000, Avg. loss: 0.342546\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 45.89, NNZs: 107587, Bias: 0.049538, T: 80000, Avg. loss: 0.278299\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 45.53, NNZs: 109702, Bias: 0.028649, T: 120000, Avg. loss: 0.266842\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 45.33, NNZs: 110494, Bias: 0.013332, T: 160000, Avg. loss: 0.261676\n",
      "Total training time: 0.08 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 45.24, NNZs: 110824, Bias: 0.023834, T: 200000, Avg. loss: 0.258857\n",
      "Total training time: 0.12 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 45.23, NNZs: 111062, Bias: 0.033027, T: 240000, Avg. loss: 0.256949\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 45.22, NNZs: 111200, Bias: 0.025426, T: 280000, Avg. loss: 0.255282\n",
      "Total training time: 0.16 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 45.20, NNZs: 111281, Bias: 0.026107, T: 320000, Avg. loss: 0.254294\n",
      "Total training time: 0.18 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 45.18, NNZs: 111316, Bias: 0.036505, T: 360000, Avg. loss: 0.253475\n",
      "Total training time: 0.19 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 45.17, NNZs: 111342, Bias: 0.031159, T: 400000, Avg. loss: 0.252856\n",
      "Total training time: 0.24 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 45.14, NNZs: 111354, Bias: 0.029406, T: 440000, Avg. loss: 0.252260\n",
      "Total training time: 0.26 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 45.13, NNZs: 111356, Bias: 0.030448, T: 480000, Avg. loss: 0.251932\n",
      "Total training time: 0.28 seconds.\n",
      "Convergence after 12 epochs took 0.28 seconds\n",
      "Count Vectorizer SGD Accuracy:  0.889\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "tv_sgd = sklearn.linear_model.SGDClassifier(verbose=0, max_iter=500)\n",
    "tv_sgd.fit(tv_x_train_vector, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = tv_sgd.predict(tv_x_test_vector)\n",
    "\n",
    "#Accuracy\n",
    "tv_sgd_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer SGD Accuracy: ', tv_sgd_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer MNB Accuracy:  0.85\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "cv_mnb = sklearn.naive_bayes.MultinomialNB()\n",
    "cv_mnb.fit(cv_x_train_vector, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = cv_mnb.predict(cv_x_test_vector)\n",
    "\n",
    "# accuracy\n",
    "cv_mnb_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer MNB Accuracy: ', cv_mnb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vectorizer MNB Accuracy:  0.8589\n"
     ]
    }
   ],
   "source": [
    "# fitting the model\n",
    "tv_mnb = sklearn.naive_bayes.MultinomialNB()\n",
    "tv_mnb.fit(tv_x_train_vector, y_train)\n",
    "\n",
    "# prediction\n",
    "y_pred = tv_mnb.predict(tv_x_test_vector)\n",
    "\n",
    "# accuracy\n",
    "tv_mnb_acc = accuracy_score(y_test, y_pred)\n",
    "print('Count Vectorizer MNB Accuracy: ', tv_mnb_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.85      0.88      0.86      4988\n",
      "    Positive       0.87      0.84      0.86      5012\n",
      "\n",
      "    accuracy                           0.86     10000\n",
      "   macro avg       0.86      0.86      0.86     10000\n",
      "weighted avg       0.86      0.86      0.86     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification_report_tfidf\n",
    "print(classification_report(y_test, y_pred, target_names=['Negative', 'Positive']))  # alphabatical order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Both logistic regression and multinomial naive bayes model performing well compared to linear support vector  machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
